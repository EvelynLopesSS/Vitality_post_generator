import streamlit as st
from pathlib import Path
import google.generativeai as genai
import os

# Configura√ß√£o do modelo e API
genai.configure(api_key=st.secrets["google"]["api_key"])

# Configura√ß√£o do modelo de gera√ß√£o
generation_config = {
    "temperature": 1,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 8192,
    "response_mime_type": "text/plain",
}

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    generation_config=generation_config,
    system_instruction=(
        "Voc√™ √© uma agente de marketing digital da clinica de est√©tica chamada Vitality N√∫cleo, "
        "que fica em Jo√£o Pessoa - PB. Seu trabalho √© fazer posts para o Instagram, de acordo com "
        "as instru√ß√µes e imagens fornecidas pelo usu√°rio. O post deve come√ßar com uma frase de efeito, "
        "usar hashtags apropriadas e sempre incluir #vitalitynucleo. O m√©dico respons√°vel √© Dr. Elton En√©as "
        "(Instagram: @elton_eneas)."
    ),
)

# Fun√ß√£o para fazer upload da imagem no Google Gemini
def upload_to_gemini(path, mime_type=None):
    file = genai.upload_file(path, mime_type=mime_type)
    return file

# Fun√ß√£o principal para gera√ß√£o do post
def generate_instagram_post(image_file, user_input, chat_session=None):
    file_uploaded = upload_to_gemini(image_file)
    
    if chat_session is None:
        # Come√ßar uma nova conversa se n√£o houver sess√£o ativa
        chat_session = model.start_chat(
            history=[{"role": "user", "parts": [file_uploaded, user_input]}]
        )
    else:
        # Enviar a mensagem para o chat em andamento
        chat_session.send_message(user_input)

    # Resposta gerada pelo modelo
    response = chat_session.send_message(user_input)
    return response.text, chat_session

# Interface do Streamlit
def main():
    st.image('https://path_to_your_image', use_column_width=True)  # Substitua com a URL da imagem que deseja exibir
    st.header("üì∏ Gerar Post para Instagram - Vitality N√∫cleo ‚ú®")
    st.write("""
        Esta ferramenta permite gerar automaticamente posts para o Instagram da cl√≠nica de est√©tica. 
        Siga essas instru√ß√µes:
        - Envie uma imagem relacionada ao post.
        - Descreva brevemente o post ou fa√ßa uma pergunta.
        A ferramenta ir√° criar um post com base nessas informa√ß√µes.
    """)

    # Vari√°vel para armazenar o hist√≥rico da conversa na sess√£o do Streamlit
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []

    uploaded_file = st.file_uploader("Envie uma imagem", type=["png", "jpg", "jpeg"])
    user_input = st.text_area("Descri√ß√£o ou instru√ß√µes para o post")

    # Iniciar chat session
    chat_session = None

    if st.button("Gerar Post"):
        with st.spinner('Gerando Post ...üòÆ‚Äçüí®ü´®ü§™ü§Ø'):
            if uploaded_file is not None and user_input:
                # Salvar a imagem temporariamente
                image_path = f"temp_{uploaded_file.name}"
                with open(image_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                
                # Gerar o post e iniciar a sess√£o de chat
                post_text, chat_session = generate_instagram_post(image_path, user_input)
                
                # Atualizar o hist√≥rico com a resposta gerada
                st.session_state.chat_history.append({"role": "user", "message": user_input})
                st.session_state.chat_history.append({"role": "model", "message": post_text})

                st.balloons()
                st.subheader("Texto Gerado para o Post:")
                st.write(post_text)

                # Exibir a imagem enviada
                st.image(image_path, caption="Imagem enviada", use_column_width=True)
                
                # Remover arquivo tempor√°rio
                Path(image_path).unlink()
            else:
                st.warning("Por favor, envie uma imagem e insira a descri√ß√£o.")
    
    # Exibir o hist√≥rico da conversa
    if st.session_state.chat_history:
        st.subheader("Hist√≥rico da Conversa:")
        for msg in st.session_state.chat_history:
            if msg["role"] == "user":
                st.write(f"**Voc√™**: {msg['message']}")
            else:
                st.write(f"**Modelo**: {msg['message']}")
    
    # Op√ß√£o de pedir modifica√ß√µes
    if chat_session or st.session_state.chat_history:
        st.write("Caso queira ajustar o post, insira novos comandos abaixo:")
        modification_request = st.text_area("Solicita√ß√£o de Modifica√ß√£o", key="modification_input")
        
        if st.button("Pedir Modifica√ß√£o"):
            with st.spinner('Gerando nova vers√£o do post ...'):
                if modification_request:
                    # Adicionar a nova solicita√ß√£o ao hist√≥rico
                    st.session_state.chat_history.append({"role": "user", "message": modification_request})
                    
                    # Gerar uma nova resposta levando em conta o hist√≥rico anterior
                    complete_history = [{"role": "user", "parts": [msg["message"]]} if msg["role"] == "user"
                                        else {"role": "model", "parts": [msg["message"]]}
                                        for msg in st.session_state.chat_history]
                    
                    chat_session = model.start_chat(history=complete_history)
                    response = chat_session.send_message(modification_request)
                    
                    # Atualizar o hist√≥rico com a resposta gerada
                    st.session_state.chat_history.append({"role": "model", "message": response.text})
                    
                    st.subheader("Texto Modificado:")
                    st.write(response.text)
                else:
                    st.warning("Insira uma solicita√ß√£o de modifica√ß√£o.")
                        
if __name__ == '__main__':
    main()
